{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop, adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "cnnModel = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 118, 118, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 59, 59, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 57, 57, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                2768960   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 264       \n",
      "=================================================================\n",
      "Total params: 2,827,048\n",
      "Trainable params: 2,827,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''model.add(Convolution2D(64,(3,3),input_shape=(-1,120,120,1) ))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2 )))\n",
    "model.add(Convolution2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))           \n",
    "model.add(Convolution2D(64,(3,3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()  \n",
    " '''\n",
    "\n",
    "cnnModel.add(layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(120,120,1) ))\n",
    "\n",
    "cnnModel.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "cnnModel.add(layers.Conv2D(64, (3,3), activation=\"relu\"))\n",
    "\n",
    "cnnModel.add(layers.MaxPooling2D((2,2)))\n",
    "\n",
    "cnnModel.add(layers.Conv2D(64, (3,3), activation=\"relu\" ))\n",
    "\n",
    "cnnModel.add(layers.Flatten())\n",
    "\n",
    "cnnModel.add(layers.Dense(64, activation=\"relu\" ))\n",
    "\n",
    "cnnModel.add(layers.Dense(32, activation=\"relu\" ))\n",
    "\n",
    "cnnModel.add(layers.Dense(8, activation=\"softmax\" )) # number of classes\n",
    "\n",
    "cnnModel.summary()\n",
    "\n",
    "\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445\n",
      "['fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'fear', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'disgust', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'sadness', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'happiness', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt', 'contempt']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "images=tf.keras.dataset.images\n",
    "\n",
    "             \n",
    "(X_train,Y_train),(X_test,Y_test)=images.load_data()\n",
    "\n",
    "X_train=X_train.reshape(60000,28,28,1)\n",
    "Y_train=Y_train.astype('float32')/255\n",
    "             \n",
    "X_test=X_test.reshape(10000,28,28,1)\n",
    "Y_test=Y_test.astype('float32')/255\n",
    "    \n",
    "Y_train=tf.keras.utils.to_categorical(Y_train)\n",
    "Y_test=tf.keras.utils.to_categorical(Y_test)\n",
    "             \n",
    "             \n",
    "'''\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "imgs = []\n",
    "path = \"/root/Desktop/Piyush/ckpFace\"\n",
    "source_path=path\n",
    "for child in os.listdir(source_path):\n",
    "    sub_path = os.path.join(source_path, child)\n",
    "    if os.path.isdir(sub_path):\n",
    "        for data_file in os.listdir(sub_path):\n",
    "            X_i = Image.open(os.path.join(sub_path, data_file)).convert('L')\n",
    "            X_i = np.array(X_i.resize((120,120))) / 255.0\n",
    "            X.append(X_i)\n",
    "            y.append(child)\n",
    "print(len(X))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(np.array(X), np.array(y), test_size=(0.3), random_state=42, stratify = y)\n",
    "\n",
    "Xtrain = Xtrain.reshape([-1,120,120,1])\n",
    "Xtest = Xtest.reshape([-1,120,120,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "311/311 [==============================] - 7s 22ms/sample - loss: 1.9299 - acc: 0.2605\n",
      "Epoch 2/35\n",
      "311/311 [==============================] - 7s 21ms/sample - loss: 1.8099 - acc: 0.3312\n",
      "Epoch 3/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 1.7603 - acc: 0.3119\n",
      "Epoch 4/35\n",
      "311/311 [==============================] - 6s 21ms/sample - loss: 1.5823 - acc: 0.4791\n",
      "Epoch 5/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 1.4013 - acc: 0.4920\n",
      "Epoch 6/35\n",
      "311/311 [==============================] - 6s 21ms/sample - loss: 1.2823 - acc: 0.5788\n",
      "Epoch 7/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 1.0590 - acc: 0.6624\n",
      "Epoch 8/35\n",
      "311/311 [==============================] - 6s 21ms/sample - loss: 0.9165 - acc: 0.7299\n",
      "Epoch 9/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.7491 - acc: 0.7556\n",
      "Epoch 10/35\n",
      "311/311 [==============================] - 6s 21ms/sample - loss: 0.7599 - acc: 0.7267\n",
      "Epoch 11/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.6981 - acc: 0.7621\n",
      "Epoch 12/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.5374 - acc: 0.8328\n",
      "Epoch 13/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.3984 - acc: 0.8842\n",
      "Epoch 14/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.3044 - acc: 0.9164\n",
      "Epoch 15/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.2806 - acc: 0.9132\n",
      "Epoch 16/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.2199 - acc: 0.9196\n",
      "Epoch 17/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.1603 - acc: 0.9614\n",
      "Epoch 18/35\n",
      "311/311 [==============================] - 6s 21ms/sample - loss: 0.1272 - acc: 0.9614\n",
      "Epoch 19/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.0919 - acc: 0.9775\n",
      "Epoch 20/35\n",
      "311/311 [==============================] - 6s 21ms/sample - loss: 0.1155 - acc: 0.9711\n",
      "Epoch 21/35\n",
      "311/311 [==============================] - 7s 21ms/sample - loss: 0.0780 - acc: 0.9839\n",
      "Epoch 22/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.0733 - acc: 0.9871\n",
      "Epoch 23/35\n",
      "311/311 [==============================] - 6s 21ms/sample - loss: 0.0721 - acc: 0.9839\n",
      "Epoch 24/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.0615 - acc: 0.9871\n",
      "Epoch 25/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.0308 - acc: 0.9936\n",
      "Epoch 26/35\n",
      "311/311 [==============================] - 7s 21ms/sample - loss: 0.0221 - acc: 0.9968\n",
      "Epoch 27/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 28/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.0175 - acc: 0.9968\n",
      "Epoch 29/35\n",
      "311/311 [==============================] - 7s 21ms/sample - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 30/35\n",
      "311/311 [==============================] - 7s 21ms/sample - loss: 0.0176 - acc: 0.9968\n",
      "Epoch 31/35\n",
      "311/311 [==============================] - 6s 21ms/sample - loss: 0.0118 - acc: 0.9968\n",
      "Epoch 32/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 33/35\n",
      "311/311 [==============================] - 7s 21ms/sample - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 34/35\n",
      "311/311 [==============================] - 6s 21ms/sample - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 35/35\n",
      "311/311 [==============================] - 6s 20ms/sample - loss: 0.0035 - acc: 1.0000\n",
      "134/134 [==============================] - 1s 6ms/sample - loss: 2.1060 - acc: 0.6567\n",
      "0.6567164\n"
     ]
    }
   ],
   "source": [
    "cnnModel.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "cnnModel.fit(Xtrain,Ytrain,epochs=35,batch_size=64)\n",
    "             \n",
    "             \n",
    "testLoss,testAccuracy=cnnModel.evaluate(Xtest,Ytest)\n",
    "print(testAccuracy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.0023926813529738466\n",
      "Train Accuracy 100.0\n",
      "Train loss 2.1059744108968705\n",
      "Test Accuracy 65.67164063453674\n"
     ]
    }
   ],
   "source": [
    "train_score=cnnModel.evaluate(Xtrain,Ytrain,verbose=0)\n",
    "print('Train loss',train_score[0])\n",
    "print('Train Accuracy',100*train_score[1])\n",
    "\n",
    "test_score=cnnModel.evaluate(Xtest,Ytest,verbose=0)\n",
    "print('Train loss',test_score[0])\n",
    "print('Test Accuracy',100*test_score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 7 0 7 5 2 4 5 4 0 5 1 2 0 5 0 5 7 4 6 7 2 5 4 7 0 7 7 7 2 6 0 5 2 3 7\n",
      " 0 4 5 5 6 5 4 5 2 5 7 4 5 3 7 5 6 5 0 7 6 4 7 1 2 7 5 6 6 5 7 2 3 5 5 5 5\n",
      " 5 7 2 5 2 7 7 4 4 5 7 6 5 4 0 5 7 5 5 2 4 0 4 7 5 7 1 0 7 4 2 6 2 5 4 3 5\n",
      " 5 5 5 0 3 1 6 2 0 5 1 2 5 5 2 5 4 5 4 5 2 6 2]\n"
     ]
    }
   ],
   "source": [
    "predicted=cnnModel.predict(Xtest)\n",
    "predicted=np.argmax(np.round(predicted),axis=1)\n",
    "Ytest=np.argmax(Ytest,axis=1)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  1  3  0  0  2  4  0]\n",
      " [ 0  1  1  0  0  3  0  0]\n",
      " [ 2  0 12  0  0  3  1  0]\n",
      " [ 0  0  0  4  0  2  1  0]\n",
      " [ 0  1  1  0 18  1  0  0]\n",
      " [ 3  1  0  1  0 27  4  0]\n",
      " [ 4  0  0  0  0  2  1  1]\n",
      " [ 0  1  1  0  0  1  0 22]]\n"
     ]
    }
   ],
   "source": [
    "cm=confusion_matrix(Ytest, predicted)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "path = \"/root/Desktop/Piyush/Facial/images\"\n",
    "valid_images = [\".jpg\",\".gif\",\".png\",\".tga\"]\n",
    "for f in os.listdir(path):\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue  \n",
    "    x_i = (Image.open(os.path.join(path,f)))\n",
    "    x_i= x_i.convert('L')\n",
    "    x_i = np.array(x_i.resize((120,120))) / 255.0\n",
    "    X.append(x_i)\n",
    "    y.append(f)\n",
    "    '''X_i = Image.open(os.path.join(sub_path, data_file)).convert('L')\n",
    "            X_i = np.array(X_i.resize((120,120))) / 255.0\n",
    "            X.append(X_i)\n",
    "            y.append(child)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
